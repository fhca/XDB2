{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "    https://www.youtube.com/watch?v=OGxgnH8y2NM\n",
    "    https://www.youtube.com/watch?v=JcI5Vnw0b2c#t=2.98320246\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pip3 install sklearn\n",
    "    pip3 install quandl\n",
    "    pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low    Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                   \n",
      "2004-08-19  100.01  104.06   95.96  100.335  44659000.0          0.0   \n",
      "2004-08-20  101.01  109.08  100.50  108.310  22834300.0          0.0   \n",
      "2004-08-23  110.76  113.48  109.05  109.400  18256100.0          0.0   \n",
      "2004-08-24  111.24  111.60  103.57  104.870  15247300.0          0.0   \n",
      "2004-08-25  104.76  108.00  103.88  106.000   9188600.0          0.0   \n",
      "\n",
      "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
      "Date                                                                   \n",
      "2004-08-19          1.0  50.159839  52.191109  48.128568   50.322842   \n",
      "2004-08-20          1.0  50.661387  54.708881  50.405597   54.322689   \n",
      "2004-08-23          1.0  55.551482  56.915693  54.693835   54.869377   \n",
      "2004-08-24          1.0  55.792225  55.972783  51.945350   52.597363   \n",
      "2004-08-25          1.0  52.542193  54.167209  52.100830   53.164113   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2004-08-19   44659000.0  \n",
      "2004-08-20   22834300.0  \n",
      "2004-08-23   18256100.0  \n",
      "2004-08-24   15247300.0  \n",
      "2004-08-25    9188600.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "df = quandl.get('WIKI/GOOGL')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "columnas == características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume\n",
      "Date                                                     \n",
      "2004-08-19   50.322842  3.712563    0.324968   44659000.0\n",
      "2004-08-20   54.322689  0.710922    7.227007   22834300.0\n",
      "2004-08-23   54.869377  3.729433   -1.227880   18256100.0\n",
      "2004-08-24   52.597363  6.417469   -5.726357   15247300.0\n",
      "2004-08-25   53.164113  1.886792    1.183658    9188600.0\n"
     ]
    }
   ],
   "source": [
    "df = df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "df['HL_PCT'] = (df['Adj. High'] - df['Adj. Close']) / df['Adj. Close'] * 100.0\n",
    "df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0\n",
    "df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características y etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast_out = 31\n",
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume      label\n",
      "Date                                                                \n",
      "2004-08-19   50.322842  3.712563    0.324968   44659000.0  67.739104\n",
      "2004-08-20   54.322689  0.710922    7.227007   22834300.0  69.399229\n",
      "2004-08-23   54.869377  3.729433   -1.227880   18256100.0  68.752232\n",
      "2004-08-24   52.597363  6.417469   -5.726357   15247300.0  69.639972\n",
      "2004-08-25   53.164113  1.886792    1.183658    9188600.0  69.078238\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "forecast_col = 'Adj. Close'\n",
    "df.fillna(-99999, inplace=True)\n",
    "forecast_out = int(math.ceil(0.01*len(df)))  # desplazamiento hacia arriba\n",
    "print(\"forecast_out =\", forecast_out)\n",
    "df['label'] = df[forecast_col].shift(-forecast_out)\n",
    "df.dropna(inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume       label\n",
      "Date                                                                 \n",
      "2004-08-19   50.322842  3.712563    0.324968   44659000.0   67.739104\n",
      "2004-08-20   54.322689  0.710922    7.227007   22834300.0   69.399229\n",
      "2004-08-23   54.869377  3.729433   -1.227880   18256100.0   68.752232\n",
      "2004-08-24   52.597363  6.417469   -5.726357   15247300.0   69.639972\n",
      "2004-08-25   53.164113  1.886792    1.183658    9188600.0   69.078238\n",
      "2004-08-26   54.122070  0.037068    2.820391    7094800.0   67.839414\n",
      "2004-08-27   53.239345  2.326896   -1.803885    6211700.0   68.912727\n",
      "2004-08-30   51.162935  3.411430   -3.106003    5196700.0   70.668146\n",
      "2004-08-31   51.343492  1.308977    0.048866    4917800.0   71.219849\n",
      "2004-09-01   50.280210  2.713217   -2.385589    9138200.0   72.278116\n",
      "2004-09-02   50.912161  0.847207    2.442224   15118600.0   74.810934\n",
      "2004-09-03   50.159839  1.729827   -0.931154    5152400.0   74.199045\n",
      "2004-09-07   50.947269  0.413467    0.564301    5847500.0   70.462511\n",
      "2004-09-08   51.308384  0.713587    1.548541    4985600.0   74.921275\n",
      "2004-09-09   51.313400  0.390969   -0.185366    4061700.0   86.481962\n",
      "2004-09-10   52.828075  1.167758    3.804080    8698800.0   93.990139\n",
      "2004-09-13   53.916435  0.846512    0.815905    7844100.0   91.181468\n",
      "2004-09-14   55.917612  0.457440    3.769546   10828900.0   93.272925\n",
      "2004-09-15   56.173402  1.991071    1.302460   10713000.0   96.949273\n",
      "2004-09-16   57.161452  1.605686    1.450952    9266300.0   95.615155\n",
      "2004-09-17   58.926902  0.000000    2.683097    9472500.0   98.318500\n",
      "2004-09-20   59.864797  1.876676    2.060710   10628700.0   97.736704\n",
      "2004-09-21   59.102444  2.189409   -1.963394    7228700.0   96.131750\n",
      "2004-09-22   59.373280  1.089711    0.791826    7581200.0   92.635958\n",
      "2004-09-23   60.597057  1.498096    1.666106    8535600.0   84.937193\n",
      "2004-09-24   60.100525  3.563381   -0.942382    9123400.0   86.542147\n",
      "2004-09-27   59.313094  2.215457   -1.087320    7066100.0   84.611187\n",
      "2004-09-28   63.626409  0.425666    4.713165   16929000.0   84.189886\n",
      "2004-09-29   65.742942  3.005798    3.595985   30516400.0   91.793357\n",
      "2004-09-30   65.000651  2.083333   -0.230179   13758000.0   91.281778\n",
      "...                ...       ...         ...          ...         ...\n",
      "2016-06-07  731.090000  0.768715   -0.297298    1215741.0  754.410000\n",
      "2016-06-08  742.930000  0.118450    0.463827    1615727.0  759.280000\n",
      "2016-06-09  742.520000  0.189894    0.739414     958963.0  757.520000\n",
      "2016-06-10  733.190000  0.879717   -0.375025    1452456.0  757.650000\n",
      "2016-06-13  731.880000  0.972837    0.282261    1167736.0  761.970000\n",
      "2016-06-14  733.250000  0.375043    0.540237    1329176.0  765.840000\n",
      "2016-06-15  732.190000  0.677420   -0.371469    1161701.0  791.340000\n",
      "2016-06-16  724.250000  0.847774   -0.509643    2250083.0  800.940000\n",
      "2016-06-17  704.250000  2.433795   -2.375969    4113085.0  800.120000\n",
      "2016-06-20  706.130000  1.379349   -0.588475    2282725.0  798.920000\n",
      "2016-06-21  708.880000  0.916939   -0.164777    1515918.0  797.250000\n",
      "2016-06-22  710.470000  0.526412   -0.501365    1452884.0  806.930000\n",
      "2016-06-23  714.870000  0.001399    0.607980    2125028.0  805.230000\n",
      "2016-06-24  685.200000  2.889667   -0.720112    4771780.0  807.480000\n",
      "2016-06-27  681.140000  0.320786   -0.197805    2919486.0  808.490000\n",
      "2016-06-28  691.260000  0.214087   -0.015910    1912280.0  808.200000\n",
      "2016-06-29  695.190000  0.619974    0.133956    2156218.0  807.050000\n",
      "2016-06-30  703.530000  0.034114    0.842829    2112513.0  805.960000\n",
      "2016-07-01  710.250000  0.321014    0.730393    1549160.0  801.190000\n",
      "2016-07-05  704.890000  0.458228   -0.017021    1422028.0  805.420000\n",
      "2016-07-06  708.970000  0.568430    1.304584    1445126.0  802.750000\n",
      "2016-07-07  707.260000  0.411447   -0.401346    1058698.0  799.650000\n",
      "2016-07-08  717.780000  0.016718    1.016100    1497323.0  796.950000\n",
      "2016-07-11  727.200000  0.237748    1.081427    1441113.0  796.590000\n",
      "2016-07-12  732.510000  0.421837    0.080610    1328680.0  793.600000\n",
      "2016-07-13  729.480000  0.827987   -0.821188    1021827.0  791.300000\n",
      "2016-07-14  735.800000  0.046208    0.253427    1070351.0  793.220000\n",
      "2016-07-15  735.630000  0.729987   -0.724696    1617087.0  795.820000\n",
      "2016-07-18  753.200000  0.257156    2.072068    1934900.0  791.920000\n",
      "2016-07-19  753.410000  0.422081    0.472082    1521795.0  789.680000\n",
      "\n",
      "[3000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(nota: se recompiló `numpy` con `easy_install --upgrade numpy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/preprocessing/data.py:167: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array(df.drop(['label'], 1))\n",
    "y = np.array(df['label'])\n",
    "X = preprocessing.scale(X)\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966382036675\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.723852439212\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVR(kernel='poly')\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy) # no tan bueno!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966382036675\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression(n_jobs=-1)  # tantos como aguante el procesador\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(df.drop(['label'], 1))\n",
    "X = preprocessing.scale(X)\n",
    "X_lately  = X[-forecast_out:]\n",
    "X = X[:-forecast_out]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "y = np.array(df['label'])\n",
    "y = y[:-forecast_out]  # ajusta tamaño de y\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#pickle\n",
    "# Pickling and Scaling\n",
    "# pickling == serialización\n",
    "# objetivo: evitar entrenar el clasificador varias veces, se guarda en un archivo una vez\n",
    "# entrenado\n",
    "import pickle\n",
    "# aquí el clasificador ya está entrenado, así lo guardaremos\n",
    "\n",
    "with open(\"linearregression.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "pickle_in = open('linearregression.pickle', 'rb')\n",
    "clf = pickle.load(pickle_in)\n",
    "\n",
    "# fin de pickle  \n",
    "# una vez guardado, se puede omitir el código desde la linea clf = LinearRegression()\n",
    "# se puede crear el clasificador en equipos poderosos y recuperar el pickle en una\n",
    "# máquina mas pequeña para usarlo.\n",
    "\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "forecast_set = clf.predict(X_lately)\n",
    "print(forecast_set, accuracy, forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import datetime\n",
    "\n",
    "style.use('ggplot')\n",
    "df['Forecast'] = np.nan\n",
    "\n",
    "#obtiene ultima fecha +1 \n",
    "last_date = df.iloc[-1].name\n",
    "last_unix = last_date.timestamp()\n",
    "one_day = 86400\n",
    "next_unix = last_unix + one_day\n",
    "\n",
    "for i in forecast_set:\n",
    "    next_date = datetime.datetime.fromtimestamp(next_unix)\n",
    "    next_unix += one_day\n",
    "    df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)] + [i]\n",
    "    \n",
    "df['Adj. Close'].plot()\n",
    "df['Forecast'].plot()\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teoría de regresión\n",
    "\n",
    "## regresión lineal\n",
    "\n",
    "y = mx+b\n",
    "\n",
    "m = ((x'y')-(xy)') / ( (x')^2 - (x^2)' )\n",
    "\n",
    "donde x' es la media de x (promedio)\n",
    "\n",
    "b = y' - m*(x')\n",
    "\n",
    "(ajuste a puntos que parecen formar una recta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "xs = np.array([1,2,3,4,5,6], dtype=np.float64)\n",
    "ys = np.array([5,4,6,5,6,7], dtype=np.float64)\n",
    "\n",
    "#plt.scatter(xs, ys)\n",
    "#plt.show()\n",
    "\n",
    "def best_fit_slope_and_intercept(xs, ys):\n",
    "    m = ( (mean(xs) * mean(ys) - mean(xs * ys)) /\n",
    "         (mean(xs)**2 - mean(xs**2)) )\n",
    "    b = mean(ys) - m * mean(xs)\n",
    "    return m, b\n",
    "\n",
    "m, b = best_fit_slope_and_intercept(xs, ys)\n",
    "\n",
    "pred_x = 8\n",
    "pred_y = m * pred_x + b\n",
    "\n",
    "regression_line = [m*x+b for x in xs]\n",
    "plt.scatter(xs, ys)\n",
    "plt.scatter(pred_x, pred_y, color='g')\n",
    "\n",
    "plt.plot(xs, regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error (al cuadrado)\n",
    "\n",
    "r^2 = 1 - (SE y_fit)/ (SE y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "xs = np.array([1,2,3,4,5,6], dtype=np.float64)\n",
    "ys = np.array([5,4,6,5,6,7], dtype=np.float64)\n",
    "\n",
    "#plt.scatter(xs, ys)\n",
    "#plt.show()\n",
    "\n",
    "def best_fit_slope_and_intercept(xs, ys):\n",
    "    m = ( (mean(xs) * mean(ys) - mean(xs * ys)) /\n",
    "         (mean(xs)**2 - mean(xs**2)) )\n",
    "    b = mean(ys) - m * mean(xs)\n",
    "    return m, b\n",
    "\n",
    "def squared_error(ys_orig, ys_line):  # SE\n",
    "    return sum((ys_line - ys_orig)**2)\n",
    "\n",
    "def coefficient_of_determination(ys_orig, ys_line):\n",
    "    y_mean_line = [mean(ys_orig)] * len(ys_orig)  # horizontal\n",
    "    squared_error_regr = squared_error(ys_orig, ys_line)\n",
    "    squared_error_y_mean = squared_error(ys_orig, y_mean_line)\n",
    "    return 1 - (squared_error_regr / squared_error_y_mean)\n",
    "\n",
    "m, b = best_fit_slope_and_intercept(xs, ys)\n",
    "\n",
    "# predictions\n",
    "pred_x = 8\n",
    "pred_y = m * pred_x + b\n",
    "\n",
    "# squared error\n",
    "r_squared = coefficient_of_determination(ys, regression_line)\n",
    "print(r_squared)\n",
    "\n",
    "regression_line = [m*x+b for x in xs]\n",
    "plt.scatter(xs, ys)\n",
    "plt.scatter(pred_x, pred_y, color='g')\n",
    "\n",
    "plt.plot(xs, regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datos de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import random\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "#xs = np.array([1,2,3,4,5,6], dtype=np.float64)\n",
    "#ys = np.array([5,4,6,5,6,7], dtype=np.float64)\n",
    "\n",
    "#plt.scatter(xs, ys)\n",
    "#plt.show()\n",
    "\n",
    "def best_fit_slope_and_intercept(xs, ys):\n",
    "    m = ( (mean(xs) * mean(ys) - mean(xs * ys)) /\n",
    "         (mean(xs)**2 - mean(xs**2)) )\n",
    "    b = mean(ys) - m * mean(xs)\n",
    "    return m, b\n",
    "\n",
    "def squared_error(ys_orig, ys_line):  # SE\n",
    "    return sum((ys_line - ys_orig)**2)\n",
    "\n",
    "def coefficient_of_determination(ys_orig, ys_line):\n",
    "    y_mean_line = [mean(ys_orig)] * len(ys_orig)  # horizontal\n",
    "    squared_error_regr = squared_error(ys_orig, ys_line)\n",
    "    squared_error_y_mean = squared_error(ys_orig, y_mean_line)\n",
    "    return 1 - (squared_error_regr / squared_error_y_mean)\n",
    "\n",
    "def create_dataset(hm, variance, step=2, correlation=False):\n",
    "    val = 1\n",
    "    ys = []\n",
    "    for i in range(hm):\n",
    "        y = val + random.randrange(-variance, variance)\n",
    "        ys.append(y)\n",
    "        if correlation and correlation == 'pos':\n",
    "            val += step\n",
    "        elif correlation and correlation == 'neg':\n",
    "            val -= step\n",
    "    xs = range(hm)\n",
    "    return np.array(xs, dtype=np.float64), np.array(ys, dtype=np.float64)\n",
    "\n",
    "xs, ys = create_dataset(40, 10, 2, False)\n",
    "\n",
    "m, b = best_fit_slope_and_intercept(xs, ys)\n",
    "\n",
    "# predictions\n",
    "pred_x = xs[-1] + 1\n",
    "pred_y = m * pred_x + b\n",
    "\n",
    "regression_line = [m*x+b for x in xs]\n",
    "\n",
    "# squared error\n",
    "r_squared = coefficient_of_determination(ys, regression_line)\n",
    "print(r_squared)\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.scatter(pred_x, pred_y, s=100, color='g')\n",
    "\n",
    "plt.plot(xs, regression_line)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl, math, datetime\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import matplotlib as mpl\n",
    "\n",
    "style.use('ggplot')\n",
    "mpl.rcParams['lines.linewidth'] = 0.5\n",
    "\n",
    "df = quandl.get('WIKI/GOOGL')\n",
    "df = df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "df['HL_PCT'] = (df['Adj. High'] - df['Adj. Close']) / df['Adj. Close'] * 100.0\n",
    "df['PCT_change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0\n",
    "\n",
    "\n",
    "df = df[['Adj. Close', 'HL_PCT', 'PCT_change', 'Adj. Volume']]\n",
    "\n",
    "forecast_col = 'Adj. Close'\n",
    "df.fillna(-99999, inplace=True)\n",
    "forecast_out = int(math.ceil(0.1*len(df)))  # desplazamiento hacia arriba\n",
    "df['label'] = df[forecast_col].shift(-forecast_out)\n",
    "\n",
    "X = np.array(df.drop(['label'], 1))\n",
    "X = preprocessing.scale(X)\n",
    "X_lately  = X[-forecast_out:]\n",
    "X = X[:-forecast_out]\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "y = np.array(df['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "forecast_set = clf.predict(X_lately)\n",
    "\n",
    "df['Forecast'] = np.nan\n",
    "\n",
    "#obtiene ultima fecha +1 \n",
    "last_date = df.iloc[-1].name\n",
    "last_unix = last_date.timestamp()\n",
    "one_day = 86400\n",
    "next_unix = last_unix + one_day\n",
    "\n",
    "for i in forecast_set:\n",
    "    next_date = datetime.datetime.fromtimestamp(next_unix)\n",
    "    next_unix += one_day\n",
    "    df.loc[next_date] = [np.nan for _ in range(len(df.columns)-1)] + [i]\n",
    "    \n",
    "df['Adj. Close'].plot()\n",
    "df['Forecast'].plot()\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clasificación por medio de los k - vecinos cercanos\n",
    "\n",
    "Obtiene los k vecinos más cercanos al punto a clasificar desde los datos, el punto se clasificará con la clase que tenga la mayoría de estos k-vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('breast-cancer-wisconsin.data.txt')\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "\n",
    "X = np.array(df.drop(['class'], 1))\n",
    "y = np.array(df['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier()  # default k=5\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "example_measures = np.array([[4,2,1,1,1,2,3,2,1], [4,2,1,2,4,2,3,2,1]])\n",
    "example_measures = example_measures.reshape(len(example_measures),-1)\n",
    "\n",
    "prediction = clf.predict(example_measures)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funcionamiento interno de k-vecinos cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than the total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)- np.array(predict))\n",
    "            distances.append([euclidean_distance, group])\n",
    "    votes = [i[1] for i in sorted(distances)[:k]] #ordena y toma los primeros k votos\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    \n",
    "    return vote_result\n",
    "\n",
    "result = k_nearest_neighbors(dataset, new_features, k=3)\n",
    "print(result)\n",
    "\n",
    "[[plt.scatter(*ii, s=100, color=i) for ii in dataset[i]] for i in dataset]\n",
    "plt.scatter(*new_features, color=result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Práctica con datos reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]], 'r':[[6,5],[7,7],[8,6]]}\n",
    "new_features = [5,7]\n",
    "\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warnings.warn('K is set to a value less than the total voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)- np.array(predict))\n",
    "            distances.append([euclidean_distance, group])\n",
    "    votes = [i[1] for i in sorted(distances)[:k]] #ordena y toma los primeros k votos\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    \n",
    "    return vote_result\n",
    "\n",
    "df = pd.read_csv(\"breast-cancer-wisconsin.data.txt\")\n",
    "df.replace('?', -99999, inplace=True)\n",
    "df.drop(['id'], 1, inplace=True)\n",
    "full_data = df.astype(float).values.tolist()  #convierte datos a floats\n",
    "random.shuffle(full_data)\n",
    "\n",
    "\n",
    "\n",
    "test_size = 0.2  #  %\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = full_data[:-int(test_size*len(full_data))]  # datos sin el último 20%\n",
    "test_data = full_data[-int(test_size*len(full_data)):]  # datos en el último 20%\n",
    "\n",
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1])\n",
    "\n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1])\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote = k_nearest_neighbors(train_set, data, k=5)\n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
